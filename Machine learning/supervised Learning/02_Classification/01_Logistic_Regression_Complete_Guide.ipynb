{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Complete Guide\n",
    "\n",
    "## üìö Learning Objectives\n",
    "- Understand logistic regression for binary and multi-class classification\n",
    "- Implement logistic regression with scikit-learn\n",
    "- Interpret coefficients and odds ratios\n",
    "- Handle class imbalance\n",
    "- Evaluate classification performance\n",
    "- Apply regularization techniques\n",
    "\n",
    "## üéØ What is Logistic Regression?\n",
    "\n",
    "**Logistic Regression** is a statistical method for binary classification that models the probability of a binary outcome.\n",
    "\n",
    "### Key Concepts:\n",
    "- Uses **sigmoid function** to map predictions to probabilities (0 to 1)\n",
    "- Despite the name, it's a **classification** algorithm, not regression\n",
    "- Linear decision boundary\n",
    "- Probabilistic interpretation\n",
    "\n",
    "### Sigmoid Function:\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Where: $z = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "\n",
    "### When to Use:\n",
    "‚úÖ Binary classification (Yes/No, 0/1)  \n",
    "‚úÖ Need probability estimates  \n",
    "‚úÖ Interpretable model required  \n",
    "‚úÖ Linear decision boundary acceptable  \n",
    "‚úÖ Baseline model for comparison  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.datasets import load_breast_cancer, make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Binary Classification\n",
    "### 1Ô∏è‚É£ Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.Series(cancer.target, name='diagnosis')\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"\\nTarget classes: {cancer.target_names}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass balance: {y.value_counts(normalize=True)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Class distribution\n",
    "y.value_counts().plot(kind='bar', ax=axes[0], color=['salmon', 'skyblue'], edgecolor='black')\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(cancer.target_names, rotation=0)\n",
    "\n",
    "# Feature correlation with target\n",
    "correlations = X.corrwith(y).abs().sort_values(ascending=False).head(10)\n",
    "correlations.plot(kind='barh', ax=axes[1], color='lightgreen', edgecolor='black')\n",
    "axes[1].set_title('Top 10 Features Correlated with Target', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Absolute Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Train-Test Split and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Basic Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with scaling\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=10000))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg_pipeline.predict(X_test)\n",
    "y_pred_proba = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nüìä Model Performance:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Confusion Matrix and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=cancer.target_names,\n",
    "            yticklabels=cancer.target_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "axes[1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Feature Importance (Coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients\n",
    "coefficients = logreg_pipeline.named_steps['classifier'].coef_[0]\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualize coefficients\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "colors = ['red' if x < 0 else 'green' for x in top_features['coefficient']]\n",
    "plt.barh(range(len(top_features)), top_features['coefficient'], color=colors, edgecolor='black')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Top 15 Feature Coefficients\\n(Green: Positive impact, Red: Negative impact)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpret coefficients\n",
    "print(\"\\nüí° Coefficient Interpretation:\")\n",
    "print(\"- Positive coefficient: Increases probability of malignant (class 1)\")\n",
    "print(\"- Negative coefficient: Decreases probability of malignant (class 1)\")\n",
    "print(\"- Larger absolute value: Stronger influence on prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6Ô∏è‚É£ Probability Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction probabilities\n",
    "prob_df = pd.DataFrame({\n",
    "    'true_label': y_test,\n",
    "    'predicted_prob': y_pred_proba,\n",
    "    'predicted_label': y_pred\n",
    "})\n",
    "\n",
    "# Visualize probability distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Probability distribution by true class\n",
    "for class_label in [0, 1]:\n",
    "    class_probs = prob_df[prob_df['true_label'] == class_label]['predicted_prob']\n",
    "    axes[0].hist(class_probs, bins=30, alpha=0.6, label=cancer.target_names[class_label], edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Predicted Probability', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Probability Distribution by True Class', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Probability vs Prediction\n",
    "axes[1].scatter(range(len(y_test)), y_pred_proba, \n",
    "               c=y_test, cmap='RdYlGn', alpha=0.6, edgecolors='black')\n",
    "axes[1].axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold (0.5)')\n",
    "axes[1].set_xlabel('Sample Index', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Probability', fontsize=12)\n",
    "axes[1].set_title('Predicted Probabilities (colored by true class)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Probability Statistics:\")\n",
    "print(f\"Mean probability for class 0: {prob_df[prob_df['true_label']==0]['predicted_prob'].mean():.4f}\")\n",
    "print(f\"Mean probability for class 1: {prob_df[prob_df['true_label']==1]['predicted_prob'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7Ô∏è‚É£ Regularization (L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different regularization strengths\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "penalties = ['l1', 'l2']\n",
    "\n",
    "results = []\n",
    "\n",
    "for penalty in penalties:\n",
    "    for C in C_values:\n",
    "        # Create model\n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                penalty=penalty, \n",
    "                C=C, \n",
    "                solver='liblinear' if penalty == 'l1' else 'lbfgs',\n",
    "                random_state=42,\n",
    "                max_iter=10000\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Train and evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Count non-zero coefficients\n",
    "        coef = model.named_steps['classifier'].coef_[0]\n",
    "        non_zero = np.sum(np.abs(coef) > 1e-5)\n",
    "        \n",
    "        results.append({\n",
    "            'Penalty': penalty,\n",
    "            'C': C,\n",
    "            'Accuracy': accuracy,\n",
    "            'Non-zero Features': non_zero\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Regularization Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for penalty in penalties:\n",
    "    data = results_df[results_df['Penalty'] == penalty]\n",
    "    axes[0].plot(data['C'], data['Accuracy'], marker='o', linewidth=2, label=penalty.upper())\n",
    "    axes[1].plot(data['C'], data['Non-zero Features'], marker='o', linewidth=2, label=penalty.upper())\n",
    "\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('C (Inverse Regularization Strength)', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Accuracy vs Regularization Strength', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('C (Inverse Regularization Strength)', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Non-zero Features', fontsize=12)\n",
    "axes[1].set_title('Feature Selection via Regularization', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Regularization Insights:\")\n",
    "print(\"- L1 (Lasso): Performs feature selection (some coefficients become exactly 0)\")\n",
    "print(\"- L2 (Ridge): Shrinks coefficients but keeps all features\")\n",
    "print(\"- Smaller C: Stronger regularization (simpler model)\")\n",
    "print(\"- Larger C: Weaker regularization (more complex model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8Ô∏è‚É£ Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imbalanced dataset\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    weights=[0.9, 0.1],  # 90% class 0, 10% class 1\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Imbalanced dataset class distribution:\")\n",
    "print(pd.Series(y_imb).value_counts())\n",
    "print(f\"\\nClass balance: {pd.Series(y_imb).value_counts(normalize=True)}\")\n",
    "\n",
    "# Split data\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(\n",
    "    X_imb, y_imb, test_size=0.2, random_state=42, stratify=y_imb\n",
    ")\n",
    "\n",
    "# Compare different class weight strategies\n",
    "strategies = [\n",
    "    ('No Weighting', None),\n",
    "    ('Balanced', 'balanced'),\n",
    "    ('Custom {0:1, 1:9}', {0: 1, 1: 9})\n",
    "]\n",
    "\n",
    "results_imb = []\n",
    "\n",
    "for name, class_weight in strategies:\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            max_iter=10000\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train_imb, y_train_imb)\n",
    "    y_pred = model.predict(X_test_imb)\n",
    "    \n",
    "    results_imb.append({\n",
    "        'Strategy': name,\n",
    "        'Accuracy': accuracy_score(y_test_imb, y_pred),\n",
    "        'Precision (Class 1)': precision_score(y_test_imb, y_pred),\n",
    "        'Recall (Class 1)': recall_score(y_test_imb, y_pred),\n",
    "        'F1 (Class 1)': f1_score(y_test_imb, y_pred)\n",
    "    })\n",
    "\n",
    "results_imb_df = pd.DataFrame(results_imb)\n",
    "print(\"\\nüìä Class Imbalance Handling Comparison:\")\n",
    "print(results_imb_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "results_imb_df.set_index('Strategy')[['Precision (Class 1)', 'Recall (Class 1)', 'F1 (Class 1)']].plot(\n",
    "    kind='bar', figsize=(12, 6), edgecolor='black'\n",
    ")\n",
    "plt.title('Impact of Class Weighting on Minority Class Performance', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Metric')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Class Imbalance Insights:\")\n",
    "print(\"- 'balanced': Automatically adjusts weights inversely proportional to class frequencies\")\n",
    "print(\"- Custom weights: Fine-tune based on business requirements\")\n",
    "print(\"- Trade-off: Higher recall often means lower precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multi-class Classification\n",
    "### 9Ô∏è‚É£ Multi-class Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load iris dataset (3 classes)\n",
    "iris = load_iris()\n",
    "X_multi = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y_multi = pd.Series(iris.target, name='species')\n",
    "\n",
    "print(f\"Multi-class dataset shape: {X_multi.shape}\")\n",
    "print(f\"\\nClasses: {iris.target_names}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y_multi.value_counts().sort_index())\n",
    "\n",
    "# Split data\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "# Train multi-class logistic regression\n",
    "# multi_class='multinomial' uses softmax, 'ovr' uses one-vs-rest\n",
    "multi_strategies = ['ovr', 'multinomial']\n",
    "\n",
    "for strategy in multi_strategies:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Strategy: {strategy.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    model_multi = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(\n",
    "            multi_class=strategy,\n",
    "            random_state=42,\n",
    "            max_iter=10000\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    model_multi.fit(X_train_multi, y_train_multi)\n",
    "    y_pred_multi = model_multi.predict(X_test_multi)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_multi, y_pred_multi)\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_multi, y_pred_multi, target_names=iris.target_names))\n",
    "\n",
    "# Confusion matrix for multinomial\n",
    "cm_multi = confusion_matrix(y_test_multi, y_pred_multi)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Multi-class Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Key Takeaways\n",
    "\n",
    "### Logistic Regression Advantages:\n",
    "‚úÖ **Interpretable**: Clear coefficient interpretation  \n",
    "‚úÖ **Probabilistic**: Provides probability estimates  \n",
    "‚úÖ **Fast**: Quick to train and predict  \n",
    "‚úÖ **Regularization**: Built-in L1/L2 regularization  \n",
    "‚úÖ **Multi-class**: Handles multi-class classification  \n",
    "‚úÖ **Baseline**: Excellent baseline model  \n",
    "\n",
    "### Best Practices:\n",
    "1. **Always scale features** - Logistic regression is sensitive to feature scales\n",
    "2. **Check for multicollinearity** - Highly correlated features affect interpretation\n",
    "3. **Use regularization** - Prevents overfitting, especially with many features\n",
    "4. **Handle class imbalance** - Use class_weight parameter\n",
    "5. **Evaluate with multiple metrics** - Accuracy alone can be misleading\n",
    "\n",
    "### When to Use:\n",
    "‚úÖ Need interpretable model  \n",
    "‚úÖ Probability estimates required  \n",
    "‚úÖ Linear decision boundary acceptable  \n",
    "‚úÖ Baseline for comparison  \n",
    "‚úÖ Feature selection (L1 regularization)  \n",
    "\n",
    "### When NOT to Use:\n",
    "‚ùå Non-linear decision boundaries  \n",
    "‚ùå Complex feature interactions  \n",
    "‚ùå Very high-dimensional data (use deep learning)  \n",
    "‚ùå When maximum accuracy is critical (try ensemble methods)  \n",
    "\n",
    "### Regularization Guide:\n",
    "- **L1 (Lasso)**: Use for feature selection, sparse models\n",
    "- **L2 (Ridge)**: Use for general regularization, keeps all features\n",
    "- **C parameter**: Smaller C = stronger regularization\n",
    "\n",
    "### Class Imbalance:\n",
    "- Use `class_weight='balanced'` for automatic weighting\n",
    "- Custom weights for business-specific requirements\n",
    "- Monitor precision and recall, not just accuracy\n",
    "\n",
    "### Multi-class Strategies:\n",
    "- **OVR (One-vs-Rest)**: Faster, works well in practice\n",
    "- **Multinomial**: More accurate, uses softmax\n",
    "\n",
    "### Next Steps:\n",
    "1. Try different regularization strengths\n",
    "2. Experiment with feature engineering\n",
    "3. Compare with other classifiers\n",
    "4. Use in ensemble methods\n",
    "5. Deploy with probability calibration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
