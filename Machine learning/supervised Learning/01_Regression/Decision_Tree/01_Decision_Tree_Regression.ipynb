{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Decision Tree and Random Forest Regression\n",
                "\n",
                "This notebook demonstrates Decision Tree and Random Forest regression using Scikit-Learn Pipelines to prevent data leakage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np \n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data",
            "metadata": {},
            "source": [
                "### 1️⃣ Load & Split Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "load_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training set: (16512, 12) Testing set: (4128, 12)\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(\"./data/dataset_processed.csv\")\n",
                "# Assuming the structure is consistent with other notebooks\n",
                "target_column = 'median_house_value'\n",
                "X = df.drop(columns=[target_column])\n",
                "y = df[target_column]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(\"Training set:\", X_train.shape, \"Testing set:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pipeline_setup",
            "metadata": {},
            "source": [
                "### 2️⃣ Preprocessing Pipeline\n",
                "Using OneHotEncoder for categorical variables and Imputation for missing values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "pipeline_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "\n",
                "# Tree models technically don't need scaling, but imputation is required.\n",
                "# We will skip scaling for Trees to keep it raw, but OneHot is crucial.\n",
                "num_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median'))\n",
                "])\n",
                "\n",
                "cat_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', num_transformer, num_cols),\n",
                "        ('cat', cat_transformer, cat_cols)\n",
                "    ])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dt_model",
            "metadata": {},
            "source": [
                "### 3️⃣ Decision Tree Regressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "dt_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Decision Tree (Default) ---\n",
                        "MSE: 0.3678142093817326\n",
                        "MAE: 0.3857863777119708\n",
                        "R2: 0.6262517053766988\n"
                    ]
                }
            ],
            "source": [
                "dt_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                              ('regressor', DecisionTreeRegressor(random_state=42))])\n",
                "\n",
                "dt_pipeline.fit(X_train, y_train)\n",
                "y_pred_dt = dt_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- Decision Tree (Default) ---\")\n",
                "print(\"MSE:\", mean_squared_error(y_test, y_pred_dt))\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred_dt))\n",
                "print(\"R2:\", r2_score(y_test, y_pred_dt))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dt_tuned",
            "metadata": {},
            "source": [
                "### 4️⃣ Tuned Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "dt_tuned_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Decision Tree (Tuned) ---\n",
                        "MSE: 0.2776691150991211\n",
                        "MAE: 0.34355424631422\n",
                        "R2: 0.7178511444343025\n"
                    ]
                }
            ],
            "source": [
                "dt_tuned_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                                    ('regressor', DecisionTreeRegressor(max_depth=20, min_samples_leaf=10, random_state=42))])\n",
                "\n",
                "dt_tuned_pipeline.fit(X_train, y_train)\n",
                "y_pred_tuned = dt_tuned_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- Decision Tree (Tuned) ---\")\n",
                "print(\"MSE:\", mean_squared_error(y_test, y_pred_tuned))\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred_tuned))\n",
                "print(\"R2:\", r2_score(y_test, y_pred_tuned))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "rf_model",
            "metadata": {},
            "source": [
                "### 5️⃣ Random Forest Regressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "rf_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Random Forest ---\n",
                        "MAE: 0.284503275663723\n",
                        "R2: 0.8015792793156713\n"
                    ]
                }
            ],
            "source": [
                "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                              ('regressor', RandomForestRegressor(n_estimators=100, max_depth=30, min_samples_leaf=5, random_state=42, n_jobs=-1))])\n",
                "\n",
                "rf_pipeline.fit(X_train, y_train)\n",
                "y_pred_rf = rf_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- Random Forest ---\")\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
                "print(\"R2:\", r2_score(y_test, y_pred_rf))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cv_rf",
            "metadata": {},
            "source": [
                "### 6️⃣ Cross-Validation (Random Forest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "cv_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CV R2 Mean: 0.8089284235623875\n"
                    ]
                }
            ],
            "source": [
                "cv_r2 = cross_val_score(rf_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
                "print(\"CV R2 Mean:\", cv_r2.mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feat_imp",
            "metadata": {},
            "source": [
                "### 7️⃣ Feature Importance\n",
                "Extracting feature importance from the pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "feat_imp_code",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "median_income         0.556659\n",
                            "longitude             0.157195\n",
                            "latitude              0.145720\n",
                            "housing_median_age    0.061812\n",
                            "population            0.029209\n",
                            "total_bedrooms        0.021513\n",
                            "total_rooms           0.015891\n",
                            "households            0.012001\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Update the preprocessor pipeline to handle only numerical columns\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', num_transformer, num_cols)\n",
                "    ])\n",
                "\n",
                "# Fit the preprocessor pipeline on the training data\n",
                "preprocessor.fit(X_train)\n",
                "\n",
                "# Get importances\n",
                "importances = rf_pipeline.named_steps['regressor'].feature_importances_\n",
                "\n",
                "feature_importances = pd.Series(importances, index=num_cols)\n",
                "feature_importances = feature_importances.sort_values(ascending=False)\n",
                "feature_importances.head(10)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ml_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
