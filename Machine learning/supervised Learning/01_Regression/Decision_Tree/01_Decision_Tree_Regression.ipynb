{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Decision Tree and Random Forest Regression\n",
                "\n",
                "This notebook demonstrates Decision Tree and Random Forest regression using Scikit-Learn Pipelines to prevent data leakage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np \n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data",
            "metadata": {},
            "source": [
                "### 1️⃣ Load & Split Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"../Linear Regression/data/dataset.csv\") # Adjust path if needed or use absolute\n",
                "# Assuming the structure is consistent with other notebooks\n",
                "target_column = 'median_house_value'\n",
                "X = df.drop(columns=[target_column])\n",
                "y = df[target_column]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(\"Training set:\", X_train.shape, \"Testing set:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pipeline_setup",
            "metadata": {},
            "source": [
                "### 2️⃣ Preprocessing Pipeline\n",
                "Using OneHotEncoder for categorical variables and Imputation for missing values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "pipeline_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "\n",
                "# Tree models technically don't need scaling, but imputation is required.\n",
                "# We will skip scaling for Trees to keep it raw, but OneHot is crucial.\n",
                "num_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median'))\n",
                "])\n",
                "\n",
                "cat_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', num_transformer, num_cols),\n",
                "        ('cat', cat_transformer, cat_cols)\n",
                "    ])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dt_model",
            "metadata": {},
            "source": [
                "### 3️⃣ Decision Tree Regressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dt_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "dt_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                              ('regressor', DecisionTreeRegressor(random_state=42))])\n",
                "\n",
                "dt_pipeline.fit(X_train, y_train)\n",
                "y_pred_dt = dt_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- Decision Tree (Default) ---\")\n",
                "print(\"MSE:\", mean_squared_error(y_test, y_pred_dt))\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred_dt))\n",
                "print(\"R2:\", r2_score(y_test, y_pred_dt))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dt_tuned",
            "metadata": {},
            "source": [
                "### 4️⃣ Tuned Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dt_tuned_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "dt_tuned_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                                    ('regressor', DecisionTreeRegressor(max_depth=20, min_samples_leaf=10, random_state=42))])\n",
                "\n",
                "dt_tuned_pipeline.fit(X_train, y_train)\n",
                "y_pred_tuned = dt_tuned_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- Decision Tree (Tuned) ---\")\n",
                "print(\"MSE:\", mean_squared_error(y_test, y_pred_tuned))\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred_tuned))\n",
                "print(\"R2:\", r2_score(y_test, y_pred_tuned))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "rf_model",
            "metadata": {},
            "source": [
                "### 5️⃣ Random Forest Regressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "rf_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                              ('regressor', RandomForestRegressor(n_estimators=100, max_depth=30, min_samples_leaf=5, random_state=42, n_jobs=-1))])\n",
                "\n",
                "rf_pipeline.fit(X_train, y_train)\n",
                "y_pred_rf = rf_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- Random Forest ---\")\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
                "print(\"R2:\", r2_score(y_test, y_pred_rf))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cv_rf",
            "metadata": {},
            "source": [
                "### 6️⃣ Cross-Validation (Random Forest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cv_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "cv_r2 = cross_val_score(rf_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
                "print(\"CV R2 Mean:\", cv_r2.mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feat_imp",
            "metadata": {},
            "source": [
                "### 7️⃣ Feature Importance\n",
                "Extracting feature importance from the pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feat_imp_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature names from preprocessor\n",
                "ohe = preprocessor.named_transformers_['cat']['onehot']\n",
                "cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
                "all_feature_names = num_cols + list(cat_feature_names)\n",
                "\n",
                "# Get importances\n",
                "importances = rf_pipeline.named_steps['regressor'].feature_importances_\n",
                "\n",
                "feature_importances = pd.Series(importances, index=all_feature_names)\n",
                "feature_importances = feature_importances.sort_values(ascending=False)\n",
                "feature_importances.head(10)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}