{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro_markdown",
            "metadata": {},
            "source": [
                "# Ridge and Lasso Regression\n",
                "\n",
                "Regularized linear models are finding a new line that doesn't fit the training data as well as ordinary least squares regression, in order to achieve better generalization to new data. This is particularly useful when dealing with multicollinearity or when the number of predictors exceeds the number of observations.\n",
                "\n",
                "- **Ridge (L2 Regularization)**: Adds a penalty equal to the square of the magnitude of coefficients. Shrinks coefficients towards zero but rarely makes them exactly zero.\n",
                "- **Lasso (L1 Regularization)**: Adds a penalty equal to the absolute value of the magnitude of coefficients. Can shrink coefficients to exactly zero, effectively performing feature selection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LassoCV\n",
                "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_load",
            "metadata": {},
            "source": [
                "### 1️⃣ Load Data & Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_split_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"data/dataset.csv\")\n",
                "target_column = 'median_house_value'\n",
                "X = df.drop(columns=[target_column])\n",
                "y = df[target_column]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(\"Training set:\", X_train.shape, \"Testing set:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "preprocessor",
            "metadata": {},
            "source": [
                "### 2️⃣ Preprocessing Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "pp_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "\n",
                "num_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "cat_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', num_transformer, num_cols),\n",
                "        ('cat', cat_transformer, cat_cols)\n",
                "    ])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "metrics_func",
            "metadata": {},
            "outputs": [],
            "source": [
                "def regression_metrics(y_true, y_pred, model_name):\n",
                "    mse = mean_squared_error(y_true, y_pred)\n",
                "    rmse = np.sqrt(mse)\n",
                "    mae = mean_absolute_error(y_true, y_pred)\n",
                "    r2 = r2_score(y_true, y_pred)\n",
                "    print(f\"--- {model_name} ---\")\n",
                "    print(f\"MSE: {mse:.4f}\")\n",
                "    print(f\"RMSE: {rmse:.4f}\")\n",
                "    print(f\"MAE: {mae:.4f}\")\n",
                "    print(f\"R²: {r2:.4f}\")\n",
                "    print(\"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ridge_cv",
            "metadata": {},
            "source": [
                "### 3️⃣ Ridge Regression with Cross-Validation (RidgeCV)\n",
                "RidgeCV automatically performs Leave-One-Out Cross-Validation to find the best `alpha`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ridge_fit",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define alphas to test\n",
                "alphas = [0.1, 1.0, 10.0, 100.0]\n",
                "\n",
                "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                                 ('regressor', RidgeCV(alphas=alphas, scoring='neg_mean_squared_error'))])\n",
                "\n",
                "ridge_pipeline.fit(X_train, y_train)\n",
                "\n",
                "# Best Alpha\n",
                "best_alpha_ridge = ridge_pipeline.named_steps['regressor'].alpha_\n",
                "print(f\"Best Alpha for Ridge: {best_alpha_ridge}\")\n",
                "\n",
                "# Evaluate\n",
                "y_pred_ridge = ridge_pipeline.predict(X_test)\n",
                "regression_metrics(y_test, y_pred_ridge, \"Ridge Regression (Tuned)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "lasso_cv",
            "metadata": {},
            "source": [
                "### 4️⃣ Lasso Regression with Cross-Validation (LassoCV)\n",
                "LassoCV tests multiple alphas to find the one that minimizes error."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "lasso_fit",
            "metadata": {},
            "outputs": [],
            "source": [
                "lasso_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                                 ('regressor', LassoCV(cv=5, random_state=42))])\n",
                "\n",
                "lasso_pipeline.fit(X_train, y_train)\n",
                "\n",
                "# Best Alpha\n",
                "best_alpha_lasso = lasso_pipeline.named_steps['regressor'].alpha_\n",
                "print(f\"Best Alpha for Lasso: {best_alpha_lasso}\")\n",
                "\n",
                "# Evaluate\n",
                "y_pred_lasso = lasso_pipeline.predict(X_test)\n",
                "regression_metrics(y_test, y_pred_lasso, \"Lasso Regression (Tuned)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "viz",
            "metadata": {},
            "source": [
                "### 5️⃣ Visualization: Actual vs Predicted (Ridge)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "viz_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8,6))\n",
                "plt.scatter(y_test, y_pred_ridge, alpha=0.6, label='Ridge Predictions')\n",
                "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
                "plt.xlabel(\"Actual Values\")\n",
                "plt.ylabel(\"Predicted Values\")\n",
                "plt.title(f\"Ridge Regression (Alpha={best_alpha_ridge})\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}