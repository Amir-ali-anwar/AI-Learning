{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Feature Engineering - Complete Guide\n",
                "\n",
                "## üìö Learning Objectives\n",
                "- Master feature creation techniques\n",
                "- Learn feature transformation methods\n",
                "- Implement feature selection strategies\n",
                "- Handle different data types effectively\n",
                "- Create domain-specific features\n",
                "- Optimize feature sets for ML models\n",
                "\n",
                "## üéØ What is Feature Engineering?\n",
                "\n",
                "**Feature Engineering** is the process of using domain knowledge to create features that make machine learning algorithms work better.\n",
                "\n",
                "### Why is it Important?\n",
                "> \"Coming up with features is difficult, time-consuming, requires expert knowledge. 'Applied machine learning' is basically feature engineering.\" - Andrew Ng\n",
                "\n",
                "### Impact on Model Performance:\n",
                "- Good features can improve model accuracy by 10-50%\n",
                "- Often more important than algorithm choice\n",
                "- Can reduce training time significantly\n",
                "- Makes models more interpretable\n",
                "\n",
                "### Categories of Feature Engineering:\n",
                "1. **Feature Creation**: Creating new features from existing ones\n",
                "2. **Feature Transformation**: Changing the scale or distribution\n",
                "3. **Feature Selection**: Choosing the most relevant features\n",
                "4. **Feature Extraction**: Reducing dimensionality (PCA, etc.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import (\n",
                "    StandardScaler, MinMaxScaler, RobustScaler,\n",
                "    LabelEncoder, OneHotEncoder, OrdinalEncoder,\n",
                "    PolynomialFeatures, PowerTransformer\n",
                ")\n",
                "from sklearn.feature_selection import (\n",
                "    SelectKBest, f_regression, mutual_info_regression,\n",
                "    RFE, SelectFromModel\n",
                ")\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "from scipy import stats\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Feature Creation\n",
                "### 1Ô∏è‚É£ Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load California Housing dataset\n",
                "df = pd.read_csv('supervised Learning/01_Regression/Linear Regression/data/dataset.csv')\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(f\"\\nColumns: {list(df.columns)}\")\n",
                "print(f\"\\nFirst few rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2Ô∏è‚É£ Mathematical Features\n",
                "Creating new features using mathematical operations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a copy for feature engineering\n",
                "df_fe = df.copy()\n",
                "\n",
                "print(\"üîß Creating Mathematical Features...\\n\")\n",
                "\n",
                "# 1. Ratio Features\n",
                "df_fe['rooms_per_household'] = df_fe['total_rooms'] / df_fe['households']\n",
                "df_fe['bedrooms_per_room'] = df_fe['total_bedrooms'] / df_fe['total_rooms']\n",
                "df_fe['population_per_household'] = df_fe['population'] / df_fe['households']\n",
                "\n",
                "print(\"‚úÖ Ratio features created:\")\n",
                "print(\"  - rooms_per_household\")\n",
                "print(\"  - bedrooms_per_room\")\n",
                "print(\"  - population_per_household\")\n",
                "\n",
                "# 2. Interaction Features\n",
                "df_fe['income_per_room'] = df_fe['median_income'] * df_fe['rooms_per_household']\n",
                "df_fe['income_age_interaction'] = df_fe['median_income'] * df_fe['housing_median_age']\n",
                "\n",
                "print(\"\\n‚úÖ Interaction features created:\")\n",
                "print(\"  - income_per_room\")\n",
                "print(\"  - income_age_interaction\")\n",
                "\n",
                "# 3. Aggregation Features\n",
                "df_fe['total_rooms_bedrooms'] = df_fe['total_rooms'] + df_fe['total_bedrooms']\n",
                "df_fe['avg_rooms_bedrooms'] = (df_fe['total_rooms'] + df_fe['total_bedrooms']) / 2\n",
                "\n",
                "print(\"\\n‚úÖ Aggregation features created:\")\n",
                "print(\"  - total_rooms_bedrooms\")\n",
                "print(\"  - avg_rooms_bedrooms\")\n",
                "\n",
                "# 4. Polynomial Features (for specific columns)\n",
                "df_fe['median_income_squared'] = df_fe['median_income'] ** 2\n",
                "df_fe['median_income_cubed'] = df_fe['median_income'] ** 3\n",
                "\n",
                "print(\"\\n‚úÖ Polynomial features created:\")\n",
                "print(\"  - median_income_squared\")\n",
                "print(\"  - median_income_cubed\")\n",
                "\n",
                "print(f\"\\nüìä New dataset shape: {df_fe.shape}\")\n",
                "print(f\"Added {df_fe.shape[1] - df.shape[1]} new features!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3Ô∏è‚É£ Binning/Discretization\n",
                "Converting continuous variables into categorical bins"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîß Creating Binned Features...\\n\")\n",
                "\n",
                "# 1. Equal-width binning\n",
                "df_fe['income_category'] = pd.cut(\n",
                "    df_fe['median_income'],\n",
                "    bins=5,\n",
                "    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
                ")\n",
                "\n",
                "# 2. Quantile-based binning\n",
                "df_fe['age_quartile'] = pd.qcut(\n",
                "    df_fe['housing_median_age'],\n",
                "    q=4,\n",
                "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
                ")\n",
                "\n",
                "# 3. Custom binning\n",
                "def categorize_rooms(rooms):\n",
                "    if rooms < 3:\n",
                "        return 'Small'\n",
                "    elif rooms < 6:\n",
                "        return 'Medium'\n",
                "    else:\n",
                "        return 'Large'\n",
                "\n",
                "df_fe['household_size_category'] = df_fe['rooms_per_household'].apply(categorize_rooms)\n",
                "\n",
                "print(\"‚úÖ Binned features created:\")\n",
                "print(\"  - income_category (5 bins)\")\n",
                "print(\"  - age_quartile (4 quartiles)\")\n",
                "print(\"  - household_size_category (custom)\")\n",
                "\n",
                "# Visualize binning\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "df_fe['income_category'].value_counts().plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')\n",
                "axes[0].set_title('Income Categories', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "df_fe['age_quartile'].value_counts().plot(kind='bar', ax=axes[1], color='lightcoral', edgecolor='black')\n",
                "axes[1].set_title('Age Quartiles', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('Count')\n",
                "\n",
                "df_fe['household_size_category'].value_counts().plot(kind='bar', ax=axes[2], color='lightgreen', edgecolor='black')\n",
                "axes[2].set_title('Household Size Categories', fontsize=14, fontweight='bold')\n",
                "axes[2].set_ylabel('Count')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4Ô∏è‚É£ Date/Time Features\n",
                "Extracting features from datetime columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create sample datetime data\n",
                "print(\"üîß Creating Date/Time Features...\\n\")\n",
                "\n",
                "# Simulate a date column\n",
                "np.random.seed(42)\n",
                "df_fe['sale_date'] = pd.date_range(start='2020-01-01', periods=len(df_fe), freq='H')\n",
                "\n",
                "# Extract datetime features\n",
                "df_fe['year'] = df_fe['sale_date'].dt.year\n",
                "df_fe['month'] = df_fe['sale_date'].dt.month\n",
                "df_fe['day'] = df_fe['sale_date'].dt.day\n",
                "df_fe['day_of_week'] = df_fe['sale_date'].dt.dayofweek\n",
                "df_fe['hour'] = df_fe['sale_date'].dt.hour\n",
                "df_fe['is_weekend'] = (df_fe['day_of_week'] >= 5).astype(int)\n",
                "df_fe['quarter'] = df_fe['sale_date'].dt.quarter\n",
                "df_fe['is_month_start'] = df_fe['sale_date'].dt.is_month_start.astype(int)\n",
                "df_fe['is_month_end'] = df_fe['sale_date'].dt.is_month_end.astype(int)\n",
                "\n",
                "print(\"‚úÖ Date/Time features created:\")\n",
                "print(\"  - year, month, day\")\n",
                "print(\"  - day_of_week, hour\")\n",
                "print(\"  - is_weekend, quarter\")\n",
                "print(\"  - is_month_start, is_month_end\")\n",
                "\n",
                "# Cyclical encoding for periodic features\n",
                "df_fe['month_sin'] = np.sin(2 * np.pi * df_fe['month'] / 12)\n",
                "df_fe['month_cos'] = np.cos(2 * np.pi * df_fe['month'] / 12)\n",
                "df_fe['hour_sin'] = np.sin(2 * np.pi * df_fe['hour'] / 24)\n",
                "df_fe['hour_cos'] = np.cos(2 * np.pi * df_fe['hour'] / 24)\n",
                "\n",
                "print(\"\\n‚úÖ Cyclical features created:\")\n",
                "print(\"  - month_sin, month_cos\")\n",
                "print(\"  - hour_sin, hour_cos\")\n",
                "\n",
                "print(f\"\\nüìä Total features now: {df_fe.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Feature Transformation\n",
                "### 5Ô∏è‚É£ Scaling Techniques"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select numerical features for scaling\n",
                "numerical_features = ['median_income', 'total_rooms', 'population']\n",
                "X_sample = df[numerical_features].copy()\n",
                "\n",
                "print(\"üîß Demonstrating Different Scaling Techniques...\\n\")\n",
                "print(\"Original data statistics:\")\n",
                "print(X_sample.describe())\n",
                "\n",
                "# 1. StandardScaler (Z-score normalization)\n",
                "scaler_standard = StandardScaler()\n",
                "X_standard = pd.DataFrame(\n",
                "    scaler_standard.fit_transform(X_sample),\n",
                "    columns=[f\"{col}_standard\" for col in numerical_features]\n",
                ")\n",
                "\n",
                "# 2. MinMaxScaler (0-1 scaling)\n",
                "scaler_minmax = MinMaxScaler()\n",
                "X_minmax = pd.DataFrame(\n",
                "    scaler_minmax.fit_transform(X_sample),\n",
                "    columns=[f\"{col}_minmax\" for col in numerical_features]\n",
                ")\n",
                "\n",
                "# 3. RobustScaler (robust to outliers)\n",
                "scaler_robust = RobustScaler()\n",
                "X_robust = pd.DataFrame(\n",
                "    scaler_robust.fit_transform(X_sample),\n",
                "    columns=[f\"{col}_robust\" for col in numerical_features]\n",
                ")\n",
                "\n",
                "# Visualize scaling effects\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
                "\n",
                "# Original\n",
                "X_sample['median_income'].hist(bins=50, ax=axes[0, 0], color='gray', edgecolor='black')\n",
                "axes[0, 0].set_title('Original Data', fontsize=14, fontweight='bold')\n",
                "axes[0, 0].set_xlabel('Median Income')\n",
                "\n",
                "# StandardScaler\n",
                "X_standard['median_income_standard'].hist(bins=50, ax=axes[0, 1], color='skyblue', edgecolor='black')\n",
                "axes[0, 1].set_title('StandardScaler (Mean=0, Std=1)', fontsize=14, fontweight='bold')\n",
                "axes[0, 1].set_xlabel('Scaled Value')\n",
                "\n",
                "# MinMaxScaler\n",
                "X_minmax['median_income_minmax'].hist(bins=50, ax=axes[1, 0], color='lightcoral', edgecolor='black')\n",
                "axes[1, 0].set_title('MinMaxScaler (Range: 0-1)', fontsize=14, fontweight='bold')\n",
                "axes[1, 0].set_xlabel('Scaled Value')\n",
                "\n",
                "# RobustScaler\n",
                "X_robust['median_income_robust'].hist(bins=50, ax=axes[1, 1], color='lightgreen', edgecolor='black')\n",
                "axes[1, 1].set_title('RobustScaler (Robust to Outliers)', fontsize=14, fontweight='bold')\n",
                "axes[1, 1].set_xlabel('Scaled Value')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüìä Scaling Comparison:\")\n",
                "print(\"\\nStandardScaler:\")\n",
                "print(X_standard.describe().loc[['mean', 'std']])\n",
                "print(\"\\nMinMaxScaler:\")\n",
                "print(X_minmax.describe().loc[['min', 'max']])\n",
                "print(\"\\nRobustScaler:\")\n",
                "print(X_robust.describe().loc[['50%']])  # Median should be close to 0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6Ô∏è‚É£ Handling Skewed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîß Handling Skewed Distributions...\\n\")\n",
                "\n",
                "# Check skewness\n",
                "skewed_feature = 'total_rooms'\n",
                "original_skew = df[skewed_feature].skew()\n",
                "print(f\"Original skewness of {skewed_feature}: {original_skew:.2f}\")\n",
                "\n",
                "# Different transformation techniques\n",
                "transformations = {\n",
                "    'Original': df[skewed_feature],\n",
                "    'Log Transform': np.log1p(df[skewed_feature]),\n",
                "    'Square Root': np.sqrt(df[skewed_feature]),\n",
                "    'Box-Cox': stats.boxcox(df[skewed_feature] + 1)[0],\n",
                "    'Yeo-Johnson': PowerTransformer(method='yeo-johnson').fit_transform(\n",
                "        df[[skewed_feature]]\n",
                "    ).ravel()\n",
                "}\n",
                "\n",
                "# Visualize transformations\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "axes = axes.ravel()\n",
                "\n",
                "for idx, (name, data) in enumerate(transformations.items()):\n",
                "    axes[idx].hist(data, bins=50, edgecolor='black', alpha=0.7)\n",
                "    axes[idx].set_title(f'{name}\\nSkewness: {pd.Series(data).skew():.2f}', \n",
                "                       fontsize=12, fontweight='bold')\n",
                "    axes[idx].set_xlabel('Value')\n",
                "    axes[idx].set_ylabel('Frequency')\n",
                "    axes[idx].grid(True, alpha=0.3)\n",
                "\n",
                "# Remove extra subplot\n",
                "fig.delaxes(axes[5])\n",
                "\n",
                "plt.suptitle('Comparison of Transformation Techniques', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n‚úÖ Best transformation reduces skewness closest to 0\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7Ô∏è‚É£ Encoding Categorical Variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîß Encoding Categorical Variables...\\n\")\n",
                "\n",
                "# Sample categorical data\n",
                "if 'ocean_proximity' in df.columns:\n",
                "    cat_feature = 'ocean_proximity'\n",
                "    \n",
                "    print(f\"Unique values in {cat_feature}:\")\n",
                "    print(df[cat_feature].value_counts())\n",
                "    \n",
                "    # 1. Label Encoding (for ordinal data)\n",
                "    le = LabelEncoder()\n",
                "    df_fe['ocean_proximity_label'] = le.fit_transform(df[cat_feature])\n",
                "    \n",
                "    print(\"\\n‚úÖ Label Encoding:\")\n",
                "    print(dict(zip(le.classes_, le.transform(le.classes_))))\n",
                "    \n",
                "    # 2. One-Hot Encoding (for nominal data)\n",
                "    df_onehot = pd.get_dummies(df[cat_feature], prefix='ocean', drop_first=False)\n",
                "    df_fe = pd.concat([df_fe, df_onehot], axis=1)\n",
                "    \n",
                "    print(\"\\n‚úÖ One-Hot Encoding created columns:\")\n",
                "    print(list(df_onehot.columns))\n",
                "    \n",
                "    # 3. Frequency Encoding\n",
                "    freq_encoding = df[cat_feature].value_counts(normalize=True).to_dict()\n",
                "    df_fe['ocean_proximity_freq'] = df[cat_feature].map(freq_encoding)\n",
                "    \n",
                "    print(\"\\n‚úÖ Frequency Encoding:\")\n",
                "    print(freq_encoding)\n",
                "    \n",
                "    # 4. Target Encoding (mean of target for each category)\n",
                "    target_encoding = df.groupby(cat_feature)['median_house_value'].mean().to_dict()\n",
                "    df_fe['ocean_proximity_target'] = df[cat_feature].map(target_encoding)\n",
                "    \n",
                "    print(\"\\n‚úÖ Target Encoding:\")\n",
                "    print(target_encoding)\n",
                "\n",
                "print(f\"\\nüìä Total features after encoding: {df_fe.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Feature Selection\n",
                "### 8Ô∏è‚É£ Filter Methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîß Feature Selection - Filter Methods...\\n\")\n",
                "\n",
                "# Prepare data for feature selection\n",
                "# Select only numerical features\n",
                "numerical_cols = df_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
                "numerical_cols = [col for col in numerical_cols if col not in ['median_house_value', 'sale_date']]\n",
                "\n",
                "X_fs = df_fe[numerical_cols].fillna(df_fe[numerical_cols].median())\n",
                "y_fs = df_fe['median_house_value']\n",
                "\n",
                "# 1. Correlation-based selection\n",
                "correlations = X_fs.corrwith(y_fs).abs().sort_values(ascending=False)\n",
                "\n",
                "print(\"Top 10 features by correlation with target:\")\n",
                "print(correlations.head(10))\n",
                "\n",
                "# Visualize correlations\n",
                "plt.figure(figsize=(12, 8))\n",
                "correlations.head(15).plot(kind='barh', color='skyblue', edgecolor='black')\n",
                "plt.xlabel('Absolute Correlation', fontsize=12)\n",
                "plt.title('Top 15 Features by Correlation with Target', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3, axis='x')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 2. Mutual Information\n",
                "mi_scores = mutual_info_regression(X_fs, y_fs, random_state=42)\n",
                "mi_scores = pd.Series(mi_scores, index=X_fs.columns).sort_values(ascending=False)\n",
                "\n",
                "print(\"\\nTop 10 features by Mutual Information:\")\n",
                "print(mi_scores.head(10))\n",
                "\n",
                "# 3. SelectKBest\n",
                "selector = SelectKBest(f_regression, k=10)\n",
                "X_selected = selector.fit_transform(X_fs, y_fs)\n",
                "selected_features = X_fs.columns[selector.get_support()]\n",
                "\n",
                "print(\"\\n‚úÖ Top 10 features selected by SelectKBest:\")\n",
                "print(list(selected_features))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9Ô∏è‚É£ Wrapper Methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîß Feature Selection - Wrapper Methods...\\n\")\n",
                "\n",
                "# Use a subset for faster computation\n",
                "X_subset = X_fs[correlations.head(20).index]\n",
                "\n",
                "# 1. Recursive Feature Elimination (RFE)\n",
                "estimator = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
                "rfe = RFE(estimator, n_features_to_select=10)\n",
                "\n",
                "print(\"Running RFE... (this may take a minute)\")\n",
                "rfe.fit(X_subset, y_fs)\n",
                "\n",
                "rfe_features = X_subset.columns[rfe.support_]\n",
                "rfe_ranking = pd.Series(rfe.ranking_, index=X_subset.columns).sort_values()\n",
                "\n",
                "print(\"\\n‚úÖ Features selected by RFE:\")\n",
                "print(list(rfe_features))\n",
                "\n",
                "print(\"\\nFeature Ranking:\")\n",
                "print(rfe_ranking.head(15))\n",
                "\n",
                "# Visualize RFE ranking\n",
                "plt.figure(figsize=(12, 6))\n",
                "rfe_ranking.head(15).plot(kind='barh', color='lightcoral', edgecolor='black')\n",
                "plt.xlabel('Ranking (1 = Best)', fontsize=12)\n",
                "plt.title('RFE Feature Ranking', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3, axis='x')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîü Embedded Methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîß Feature Selection - Embedded Methods...\\n\")\n",
                "\n",
                "# 1. Feature Importance from Random Forest\n",
                "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "rf.fit(X_subset, y_fs)\n",
                "\n",
                "feature_importance = pd.Series(\n",
                "    rf.feature_importances_,\n",
                "    index=X_subset.columns\n",
                ").sort_values(ascending=False)\n",
                "\n",
                "print(\"Top 10 features by Random Forest importance:\")\n",
                "print(feature_importance.head(10))\n",
                "\n",
                "# Visualize feature importance\n",
                "plt.figure(figsize=(12, 6))\n",
                "feature_importance.head(15).plot(kind='barh', color='lightgreen', edgecolor='black')\n",
                "plt.xlabel('Importance Score', fontsize=12)\n",
                "plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3, axis='x')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 2. SelectFromModel (automatic threshold)\n",
                "selector_model = SelectFromModel(rf, threshold='median')\n",
                "selector_model.fit(X_subset, y_fs)\n",
                "\n",
                "selected_features_model = X_subset.columns[selector_model.get_support()]\n",
                "\n",
                "print(\"\\n‚úÖ Features selected by SelectFromModel:\")\n",
                "print(list(selected_features_model))\n",
                "print(f\"\\nReduced from {X_subset.shape[1]} to {len(selected_features_model)} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Impact Analysis\n",
                "### 1Ô∏è‚É£1Ô∏è‚É£ Compare Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LinearRegression\n",
                "\n",
                "print(\"üîß Comparing Model Performance with Different Feature Sets...\\n\")\n",
                "\n",
                "# Prepare different feature sets\n",
                "feature_sets = {\n",
                "    'Original Features': df[['longitude', 'latitude', 'housing_median_age', \n",
                "                            'total_rooms', 'total_bedrooms', 'population', \n",
                "                            'households', 'median_income']].fillna(method='ffill'),\n",
                "    'Engineered Features': X_subset,\n",
                "    'Selected Features (RFE)': X_subset[rfe_features],\n",
                "    'Selected Features (RF)': X_subset[selected_features_model]\n",
                "}\n",
                "\n",
                "results = {}\n",
                "\n",
                "for name, X in feature_sets.items():\n",
                "    # Split data\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y_fs, test_size=0.2, random_state=42\n",
                "    )\n",
                "    \n",
                "    # Train model\n",
                "    model = LinearRegression()\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # Evaluate\n",
                "    y_pred = model.predict(X_test)\n",
                "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
                "    r2 = r2_score(y_test, y_pred)\n",
                "    \n",
                "    results[name] = {\n",
                "        'Features': X.shape[1],\n",
                "        'RMSE': rmse,\n",
                "        'R¬≤': r2\n",
                "    }\n",
                "    \n",
                "    print(f\"{name}:\")\n",
                "    print(f\"  Features: {X.shape[1]}\")\n",
                "    print(f\"  RMSE: ${rmse:,.2f}\")\n",
                "    print(f\"  R¬≤: {r2:.4f}\\n\")\n",
                "\n",
                "# Visualize comparison\n",
                "results_df = pd.DataFrame(results).T\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "results_df['Features'].plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')\n",
                "axes[0].set_title('Number of Features', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "results_df['RMSE'].plot(kind='bar', ax=axes[1], color='lightcoral', edgecolor='black')\n",
                "axes[1].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('RMSE ($)')\n",
                "axes[1].tick_params(axis='x', rotation=45)\n",
                "\n",
                "results_df['R¬≤'].plot(kind='bar', ax=axes[2], color='lightgreen', edgecolor='black')\n",
                "axes[2].set_title('R¬≤ Score Comparison', fontsize=14, fontweight='bold')\n",
                "axes[2].set_ylabel('R¬≤ Score')\n",
                "axes[2].tick_params(axis='x', rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Key Takeaways\n",
                "\n",
                "### Feature Engineering Best Practices:\n",
                "\n",
                "#### 1. **Feature Creation**:\n",
                "‚úÖ **Domain Knowledge**: Use your understanding of the problem  \n",
                "‚úÖ **Ratios**: Often more informative than raw values  \n",
                "‚úÖ **Interactions**: Capture relationships between features  \n",
                "‚úÖ **Aggregations**: Summarize information  \n",
                "‚úÖ **Polynomial**: Capture non-linear relationships  \n",
                "\n",
                "#### 2. **Feature Transformation**:\n",
                "‚úÖ **Scaling**: Essential for distance-based algorithms  \n",
                "‚úÖ **Normalization**: Handle skewed distributions  \n",
                "‚úÖ **Encoding**: Convert categorical to numerical  \n",
                "‚úÖ **Binning**: Reduce noise and capture patterns  \n",
                "\n",
                "#### 3. **Feature Selection**:\n",
                "‚úÖ **Remove Redundant**: Eliminate highly correlated features  \n",
                "‚úÖ **Remove Irrelevant**: Use statistical tests  \n",
                "‚úÖ **Reduce Dimensionality**: Improve model performance  \n",
                "‚úÖ **Prevent Overfitting**: Fewer features = simpler model  \n",
                "\n",
                "### Common Techniques Summary:\n",
                "\n",
                "| Technique | When to Use | Pros | Cons |\n",
                "|-----------|-------------|------|------|\n",
                "| **StandardScaler** | Most cases | Preserves outliers | Sensitive to outliers |\n",
                "| **MinMaxScaler** | Bounded range needed | Simple interpretation | Sensitive to outliers |\n",
                "| **RobustScaler** | Data with outliers | Robust to outliers | Less common |\n",
                "| **Log Transform** | Right-skewed data | Simple, effective | Only for positive values |\n",
                "| **One-Hot Encoding** | Nominal categories | No ordinal assumption | High dimensionality |\n",
                "| **Label Encoding** | Ordinal categories | Low dimensionality | Implies order |\n",
                "| **Target Encoding** | High cardinality | Captures relationship | Risk of overfitting |\n",
                "\n",
                "### Feature Selection Methods:\n",
                "\n",
                "| Method | Type | Speed | Accuracy |\n",
                "|--------|------|-------|----------|\n",
                "| **Correlation** | Filter | ‚ö° Fast | Good |\n",
                "| **Mutual Information** | Filter | ‚ö° Fast | Better |\n",
                "| **RFE** | Wrapper | üêå Slow | Best |\n",
                "| **Random Forest** | Embedded | ‚ö° Fast | Good |\n",
                "| **Lasso** | Embedded | ‚ö° Fast | Good |\n",
                "\n",
                "### Workflow Recommendation:\n",
                "\n",
                "1. **Understand the Data**: EDA first!\n",
                "2. **Handle Missing Values**: Impute or remove\n",
                "3. **Create Features**: Domain-specific engineering\n",
                "4. **Transform Features**: Scale and normalize\n",
                "5. **Select Features**: Remove redundant/irrelevant\n",
                "6. **Validate**: Check impact on model performance\n",
                "7. **Iterate**: Continuously improve\n",
                "\n",
                "### Common Pitfalls:\n",
                "‚ùå **Data Leakage**: Don't use test data for feature engineering  \n",
                "‚ùå **Overfitting**: Too many features can hurt generalization  \n",
                "‚ùå **Ignoring Domain**: Generic features may not capture patterns  \n",
                "‚ùå **Not Validating**: Always check if features improve performance  \n",
                "‚ùå **Forgetting Interpretability**: Complex features are hard to explain  \n",
                "\n",
                "### Next Steps:\n",
                "1. Apply these techniques to your own datasets\n",
                "2. Experiment with different combinations\n",
                "3. Use automated feature engineering tools (Featuretools)\n",
                "4. Learn advanced techniques (deep feature synthesis)\n",
                "5. Practice on Kaggle competitions"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ml_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}